{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr"
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "houseprice = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houseprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_avg_price = pd.read_excel('https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls', sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>71306.56698</td>\n",
       "      <td>81671.47692</td>\n",
       "      <td>120932.8881</td>\n",
       "      <td>69158.16225</td>\n",
       "      <td>79885.89069</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.48001</td>\n",
       "      <td>44803.42878</td>\n",
       "      <td>45544.52227</td>\n",
       "      <td>48527.52339</td>\n",
       "      <td>56701.5961</td>\n",
       "      <td>74435.76052</td>\n",
       "      <td>64018.87894</td>\n",
       "      <td>54705.1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.77128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>72022.26197</td>\n",
       "      <td>81657.55944</td>\n",
       "      <td>119508.8622</td>\n",
       "      <td>68951.09542</td>\n",
       "      <td>80897.06551</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.42289</td>\n",
       "      <td>44528.80721</td>\n",
       "      <td>46051.57066</td>\n",
       "      <td>49341.29029</td>\n",
       "      <td>56593.59475</td>\n",
       "      <td>72777.93709</td>\n",
       "      <td>63715.02399</td>\n",
       "      <td>54356.14843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>72015.76274</td>\n",
       "      <td>81449.31143</td>\n",
       "      <td>120282.2131</td>\n",
       "      <td>68712.44341</td>\n",
       "      <td>81379.86288</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.8681</td>\n",
       "      <td>45200.46775</td>\n",
       "      <td>45383.82395</td>\n",
       "      <td>49442.17973</td>\n",
       "      <td>56171.18278</td>\n",
       "      <td>73896.84204</td>\n",
       "      <td>64113.60858</td>\n",
       "      <td>53583.07667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>72965.63094</td>\n",
       "      <td>81124.41227</td>\n",
       "      <td>120097.899</td>\n",
       "      <td>68610.04641</td>\n",
       "      <td>82188.90498</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.7796</td>\n",
       "      <td>45614.34341</td>\n",
       "      <td>46124.23045</td>\n",
       "      <td>49455.93299</td>\n",
       "      <td>56567.89582</td>\n",
       "      <td>74455.28754</td>\n",
       "      <td>64623.22395</td>\n",
       "      <td>54786.01938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.8548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>827996.60081</td>\n",
       "      <td>350239.35981</td>\n",
       "      <td>601931.6599</td>\n",
       "      <td>402667.50443</td>\n",
       "      <td>562407.51963</td>\n",
       "      <td>513498.76677</td>\n",
       "      <td>867930.22712</td>\n",
       "      <td>426105.46581</td>\n",
       "      <td>537220.87128</td>\n",
       "      <td>...</td>\n",
       "      <td>216321.72923</td>\n",
       "      <td>210137.55996</td>\n",
       "      <td>250337.29498</td>\n",
       "      <td>251926.80195</td>\n",
       "      <td>358295.87674</td>\n",
       "      <td>545608.08542</td>\n",
       "      <td>398893.43107</td>\n",
       "      <td>334116.32941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311435.11047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>827441.27622</td>\n",
       "      <td>349653.85502</td>\n",
       "      <td>605424.18481</td>\n",
       "      <td>403468.56545</td>\n",
       "      <td>584927.5386</td>\n",
       "      <td>515462.53348</td>\n",
       "      <td>857955.76149</td>\n",
       "      <td>432807.5594</td>\n",
       "      <td>540135.90519</td>\n",
       "      <td>...</td>\n",
       "      <td>218457.16</td>\n",
       "      <td>212196.46925</td>\n",
       "      <td>252252.9242</td>\n",
       "      <td>254389.50251</td>\n",
       "      <td>361500.40182</td>\n",
       "      <td>546005.12615</td>\n",
       "      <td>402606.92676</td>\n",
       "      <td>335743.93622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313884.51408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>870799.60044</td>\n",
       "      <td>355290.62346</td>\n",
       "      <td>597777.32861</td>\n",
       "      <td>409719.69933</td>\n",
       "      <td>578010.59307</td>\n",
       "      <td>522979.73425</td>\n",
       "      <td>841595.77335</td>\n",
       "      <td>434228.2722</td>\n",
       "      <td>541818.73318</td>\n",
       "      <td>...</td>\n",
       "      <td>220006.64656</td>\n",
       "      <td>212847.74493</td>\n",
       "      <td>252682.94085</td>\n",
       "      <td>256453.07431</td>\n",
       "      <td>362314.62574</td>\n",
       "      <td>539975.01492</td>\n",
       "      <td>403471.00209</td>\n",
       "      <td>337487.67124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314711.79602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>948073.2088</td>\n",
       "      <td>359495.10689</td>\n",
       "      <td>587967.70766</td>\n",
       "      <td>410407.63764</td>\n",
       "      <td>572262.24808</td>\n",
       "      <td>523810.59406</td>\n",
       "      <td>838162.23572</td>\n",
       "      <td>432216.9619</td>\n",
       "      <td>543594.15108</td>\n",
       "      <td>...</td>\n",
       "      <td>221431.98186</td>\n",
       "      <td>213389.07508</td>\n",
       "      <td>254952.86288</td>\n",
       "      <td>256139.51979</td>\n",
       "      <td>366771.68741</td>\n",
       "      <td>542910.65717</td>\n",
       "      <td>402652.10802</td>\n",
       "      <td>336748.30059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315695.90027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>968059.9863</td>\n",
       "      <td>362054.07567</td>\n",
       "      <td>595486.30411</td>\n",
       "      <td>416059.80994</td>\n",
       "      <td>566794.73925</td>\n",
       "      <td>523364.68872</td>\n",
       "      <td>842166.73612</td>\n",
       "      <td>430255.62154</td>\n",
       "      <td>548033.94229</td>\n",
       "      <td>...</td>\n",
       "      <td>221100.65258</td>\n",
       "      <td>214772.92559</td>\n",
       "      <td>256158.76167</td>\n",
       "      <td>256206.15838</td>\n",
       "      <td>363779.44643</td>\n",
       "      <td>543098.82276</td>\n",
       "      <td>404228.91584</td>\n",
       "      <td>330601.04469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315119.06969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 City of London Barking & Dagenham        Barnet        Bexley  \\\n",
       "0          NaT      E09000001          E09000002     E09000003     E09000004   \n",
       "1   1995-01-01    91448.98487         50460.2266   93284.51832   64958.09036   \n",
       "2   1995-02-01    82202.77314        51085.77983   93190.16963   64787.92069   \n",
       "3   1995-03-01    79120.70256        51268.96956   92247.52435   64367.49344   \n",
       "4   1995-04-01    77101.20804        53133.50526   90762.87492   64277.66881   \n",
       "..         ...            ...                ...           ...           ...   \n",
       "332 2022-08-01   827996.60081       350239.35981   601931.6599  402667.50443   \n",
       "333 2022-09-01   827441.27622       349653.85502  605424.18481  403468.56545   \n",
       "334 2022-10-01   870799.60044       355290.62346  597777.32861  409719.69933   \n",
       "335 2022-11-01    948073.2088       359495.10689  587967.70766  410407.63764   \n",
       "336 2022-12-01    968059.9863       362054.07567  595486.30411  416059.80994   \n",
       "\n",
       "            Brent       Bromley        Camden       Croydon        Ealing  \\\n",
       "0       E09000005     E09000006     E09000007     E09000008     E09000009   \n",
       "1     71306.56698   81671.47692   120932.8881   69158.16225   79885.89069   \n",
       "2     72022.26197   81657.55944   119508.8622   68951.09542   80897.06551   \n",
       "3     72015.76274   81449.31143   120282.2131   68712.44341   81379.86288   \n",
       "4     72965.63094   81124.41227    120097.899   68610.04641   82188.90498   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "332  562407.51963  513498.76677  867930.22712  426105.46581  537220.87128   \n",
       "333   584927.5386  515462.53348  857955.76149   432807.5594  540135.90519   \n",
       "334  578010.59307  522979.73425  841595.77335   434228.2722  541818.73318   \n",
       "335  572262.24808  523810.59406  838162.23572   432216.9619  543594.15108   \n",
       "336  566794.73925  523364.68872  842166.73612  430255.62154  548033.94229   \n",
       "\n",
       "     ...    NORTH WEST YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS  \\\n",
       "0    ...     E12000002          E12000003     E12000004     E12000005   \n",
       "1    ...   43958.48001        44803.42878   45544.52227   48527.52339   \n",
       "2    ...   43925.42289        44528.80721   46051.57066   49341.29029   \n",
       "3    ...    44434.8681        45200.46775   45383.82395   49442.17973   \n",
       "4    ...    44267.7796        45614.34341   46124.23045   49455.93299   \n",
       "..   ...           ...                ...           ...           ...   \n",
       "332  ...  216321.72923       210137.55996  250337.29498  251926.80195   \n",
       "333  ...     218457.16       212196.46925   252252.9242  254389.50251   \n",
       "334  ...  220006.64656       212847.74493  252682.94085  256453.07431   \n",
       "335  ...  221431.98186       213389.07508  254952.86288  256139.51979   \n",
       "336  ...  221100.65258       214772.92559  256158.76167  256206.15838   \n",
       "\n",
       "    EAST OF ENGLAND        LONDON    SOUTH EAST    SOUTH WEST Unnamed: 47  \\\n",
       "0         E12000006     E12000007     E12000008     E12000009         NaN   \n",
       "1        56701.5961   74435.76052   64018.87894    54705.1579         NaN   \n",
       "2       56593.59475   72777.93709   63715.02399   54356.14843         NaN   \n",
       "3       56171.18278   73896.84204   64113.60858   53583.07667         NaN   \n",
       "4       56567.89582   74455.28754   64623.22395   54786.01938         NaN   \n",
       "..              ...           ...           ...           ...         ...   \n",
       "332    358295.87674  545608.08542  398893.43107  334116.32941         NaN   \n",
       "333    361500.40182  546005.12615  402606.92676  335743.93622         NaN   \n",
       "334    362314.62574  539975.01492  403471.00209  337487.67124         NaN   \n",
       "335    366771.68741  542910.65717  402652.10802  336748.30059         NaN   \n",
       "336    363779.44643  543098.82276  404228.91584  330601.04469         NaN   \n",
       "\n",
       "          England  \n",
       "0       E92000001  \n",
       "1     53202.77128  \n",
       "2      53096.1549  \n",
       "3      53201.2843  \n",
       "4      53590.8548  \n",
       "..            ...  \n",
       "332  311435.11047  \n",
       "333  313884.51408  \n",
       "334  314711.79602  \n",
       "335  315695.90027  \n",
       "336  315119.06969  \n",
       "\n",
       "[337 rows x 49 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 337 entries, 0 to 336\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Unnamed: 0            336 non-null    datetime64[ns]\n",
      " 1   City of London        337 non-null    object        \n",
      " 2   Barking & Dagenham    337 non-null    object        \n",
      " 3   Barnet                337 non-null    object        \n",
      " 4   Bexley                337 non-null    object        \n",
      " 5   Brent                 337 non-null    object        \n",
      " 6   Bromley               337 non-null    object        \n",
      " 7   Camden                337 non-null    object        \n",
      " 8   Croydon               337 non-null    object        \n",
      " 9   Ealing                337 non-null    object        \n",
      " 10  Enfield               337 non-null    object        \n",
      " 11  Greenwich             337 non-null    object        \n",
      " 12  Hackney               337 non-null    object        \n",
      " 13  Hammersmith & Fulham  337 non-null    object        \n",
      " 14  Haringey              337 non-null    object        \n",
      " 15  Harrow                337 non-null    object        \n",
      " 16  Havering              337 non-null    object        \n",
      " 17  Hillingdon            337 non-null    object        \n",
      " 18  Hounslow              337 non-null    object        \n",
      " 19  Islington             337 non-null    object        \n",
      " 20  Kensington & Chelsea  337 non-null    object        \n",
      " 21  Kingston upon Thames  337 non-null    object        \n",
      " 22  Lambeth               337 non-null    object        \n",
      " 23  Lewisham              337 non-null    object        \n",
      " 24  Merton                337 non-null    object        \n",
      " 25  Newham                337 non-null    object        \n",
      " 26  Redbridge             337 non-null    object        \n",
      " 27  Richmond upon Thames  337 non-null    object        \n",
      " 28  Southwark             337 non-null    object        \n",
      " 29  Sutton                337 non-null    object        \n",
      " 30  Tower Hamlets         337 non-null    object        \n",
      " 31  Waltham Forest        337 non-null    object        \n",
      " 32  Wandsworth            337 non-null    object        \n",
      " 33  Westminster           337 non-null    object        \n",
      " 34  Unnamed: 34           0 non-null      float64       \n",
      " 35  Inner London          337 non-null    object        \n",
      " 36  Outer London          337 non-null    object        \n",
      " 37  Unnamed: 37           0 non-null      float64       \n",
      " 38  NORTH EAST            337 non-null    object        \n",
      " 39  NORTH WEST            337 non-null    object        \n",
      " 40  YORKS & THE HUMBER    337 non-null    object        \n",
      " 41  EAST MIDLANDS         337 non-null    object        \n",
      " 42  WEST MIDLANDS         337 non-null    object        \n",
      " 43  EAST OF ENGLAND       337 non-null    object        \n",
      " 44  LONDON                337 non-null    object        \n",
      " 45  SOUTH EAST            337 non-null    object        \n",
      " 46  SOUTH WEST            337 non-null    object        \n",
      " 47  Unnamed: 47           0 non-null      float64       \n",
      " 48  England               337 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(45)\n",
      "memory usage: 129.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_avg_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index_price = pd.read_excel('https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls', sheet_name='Index Price', index_col= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 337 entries, 0 to 336\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Unnamed: 0            336 non-null    datetime64[ns]\n",
      " 1   City of London        337 non-null    object        \n",
      " 2   Barking & Dagenham    337 non-null    object        \n",
      " 3   Barnet                337 non-null    object        \n",
      " 4   Bexley                337 non-null    object        \n",
      " 5   Brent                 337 non-null    object        \n",
      " 6   Bromley               337 non-null    object        \n",
      " 7   Camden                337 non-null    object        \n",
      " 8   Croydon               337 non-null    object        \n",
      " 9   Ealing                337 non-null    object        \n",
      " 10  Enfield               337 non-null    object        \n",
      " 11  Greenwich             337 non-null    object        \n",
      " 12  Hackney               337 non-null    object        \n",
      " 13  Hammersmith & Fulham  337 non-null    object        \n",
      " 14  Haringey              337 non-null    object        \n",
      " 15  Harrow                337 non-null    object        \n",
      " 16  Havering              337 non-null    object        \n",
      " 17  Hillingdon            337 non-null    object        \n",
      " 18  Hounslow              337 non-null    object        \n",
      " 19  Islington             337 non-null    object        \n",
      " 20  Kensington & Chelsea  337 non-null    object        \n",
      " 21  Kingston upon Thames  337 non-null    object        \n",
      " 22  Lambeth               337 non-null    object        \n",
      " 23  Lewisham              337 non-null    object        \n",
      " 24  Merton                337 non-null    object        \n",
      " 25  Newham                337 non-null    object        \n",
      " 26  Redbridge             337 non-null    object        \n",
      " 27  Richmond upon Thames  337 non-null    object        \n",
      " 28  Southwark             337 non-null    object        \n",
      " 29  Sutton                337 non-null    object        \n",
      " 30  Tower Hamlets         337 non-null    object        \n",
      " 31  Waltham Forest        337 non-null    object        \n",
      " 32  Wandsworth            337 non-null    object        \n",
      " 33  Westminster           337 non-null    object        \n",
      " 34  Unnamed: 34           0 non-null      float64       \n",
      " 35  Inner London          337 non-null    object        \n",
      " 36  Outer London          337 non-null    object        \n",
      " 37  Unnamed: 37           0 non-null      float64       \n",
      " 38  NORTH EAST            337 non-null    object        \n",
      " 39  NORTH WEST            337 non-null    object        \n",
      " 40  YORKS & THE HUMBER    337 non-null    object        \n",
      " 41  EAST MIDLANDS         337 non-null    object        \n",
      " 42  WEST MIDLANDS         337 non-null    object        \n",
      " 43  EAST OF ENGLAND       337 non-null    object        \n",
      " 44  LONDON                337 non-null    object        \n",
      " 45  SOUTH EAST            337 non-null    object        \n",
      " 46  SOUTH WEST            337 non-null    object        \n",
      " 47  Unnamed: 47           0 non-null      float64       \n",
      " 48  England               337 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(45)\n",
      "memory usage: 129.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_index_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>11.669374</td>\n",
       "      <td>22.929155</td>\n",
       "      <td>20.218477</td>\n",
       "      <td>24.816722</td>\n",
       "      <td>16.859574</td>\n",
       "      <td>21.904319</td>\n",
       "      <td>15.711197</td>\n",
       "      <td>23.945162</td>\n",
       "      <td>19.371754</td>\n",
       "      <td>...</td>\n",
       "      <td>32.312673</td>\n",
       "      <td>32.902881</td>\n",
       "      <td>29.638077</td>\n",
       "      <td>30.581484</td>\n",
       "      <td>24.839034</td>\n",
       "      <td>18.477406</td>\n",
       "      <td>24.171909</td>\n",
       "      <td>25.697918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.226925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>10.489509</td>\n",
       "      <td>23.213407</td>\n",
       "      <td>20.198028</td>\n",
       "      <td>24.75171</td>\n",
       "      <td>17.028792</td>\n",
       "      <td>21.900587</td>\n",
       "      <td>15.526192</td>\n",
       "      <td>23.873468</td>\n",
       "      <td>19.616957</td>\n",
       "      <td>...</td>\n",
       "      <td>32.288374</td>\n",
       "      <td>32.701203</td>\n",
       "      <td>29.968038</td>\n",
       "      <td>31.09431</td>\n",
       "      <td>24.791722</td>\n",
       "      <td>18.06588</td>\n",
       "      <td>24.057181</td>\n",
       "      <td>25.53397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.174367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>10.09622</td>\n",
       "      <td>23.296649</td>\n",
       "      <td>19.993719</td>\n",
       "      <td>24.591089</td>\n",
       "      <td>17.027255</td>\n",
       "      <td>21.844735</td>\n",
       "      <td>15.626663</td>\n",
       "      <td>23.790837</td>\n",
       "      <td>19.734032</td>\n",
       "      <td>...</td>\n",
       "      <td>32.662853</td>\n",
       "      <td>33.194459</td>\n",
       "      <td>29.533502</td>\n",
       "      <td>31.15789</td>\n",
       "      <td>24.606678</td>\n",
       "      <td>18.343629</td>\n",
       "      <td>24.207677</td>\n",
       "      <td>25.170817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.226192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>9.838522</td>\n",
       "      <td>24.143895</td>\n",
       "      <td>19.671936</td>\n",
       "      <td>24.556773</td>\n",
       "      <td>17.25184</td>\n",
       "      <td>21.757596</td>\n",
       "      <td>15.602718</td>\n",
       "      <td>23.755384</td>\n",
       "      <td>19.930219</td>\n",
       "      <td>...</td>\n",
       "      <td>32.540031</td>\n",
       "      <td>33.498403</td>\n",
       "      <td>30.015321</td>\n",
       "      <td>31.166557</td>\n",
       "      <td>24.780465</td>\n",
       "      <td>18.482254</td>\n",
       "      <td>24.400095</td>\n",
       "      <td>25.735903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.418235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>105.656778</td>\n",
       "      <td>159.148969</td>\n",
       "      <td>130.462619</td>\n",
       "      <td>153.835939</td>\n",
       "      <td>132.974467</td>\n",
       "      <td>137.720556</td>\n",
       "      <td>112.758599</td>\n",
       "      <td>147.533774</td>\n",
       "      <td>130.272211</td>\n",
       "      <td>...</td>\n",
       "      <td>159.012178</td>\n",
       "      <td>154.32148</td>\n",
       "      <td>162.906889</td>\n",
       "      <td>158.761363</td>\n",
       "      <td>156.956941</td>\n",
       "      <td>135.437901</td>\n",
       "      <td>150.611387</td>\n",
       "      <td>156.952194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.525479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>105.585916</td>\n",
       "      <td>158.882915</td>\n",
       "      <td>131.219589</td>\n",
       "      <td>154.141978</td>\n",
       "      <td>138.299054</td>\n",
       "      <td>138.247239</td>\n",
       "      <td>111.46275</td>\n",
       "      <td>149.854291</td>\n",
       "      <td>130.979086</td>\n",
       "      <td>...</td>\n",
       "      <td>160.581875</td>\n",
       "      <td>155.833508</td>\n",
       "      <td>164.153484</td>\n",
       "      <td>160.313329</td>\n",
       "      <td>158.360732</td>\n",
       "      <td>135.536459</td>\n",
       "      <td>152.013503</td>\n",
       "      <td>157.716767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.732941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>111.118669</td>\n",
       "      <td>161.444266</td>\n",
       "      <td>129.56221</td>\n",
       "      <td>156.530174</td>\n",
       "      <td>136.663626</td>\n",
       "      <td>140.263355</td>\n",
       "      <td>109.337314</td>\n",
       "      <td>150.346196</td>\n",
       "      <td>131.38716</td>\n",
       "      <td>...</td>\n",
       "      <td>161.72086</td>\n",
       "      <td>156.311794</td>\n",
       "      <td>164.433317</td>\n",
       "      <td>161.613768</td>\n",
       "      <td>158.717415</td>\n",
       "      <td>134.039587</td>\n",
       "      <td>152.339754</td>\n",
       "      <td>158.535892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.140759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>120.979193</td>\n",
       "      <td>163.354786</td>\n",
       "      <td>127.436074</td>\n",
       "      <td>156.792996</td>\n",
       "      <td>135.304499</td>\n",
       "      <td>140.486192</td>\n",
       "      <td>108.891241</td>\n",
       "      <td>149.649804</td>\n",
       "      <td>131.817686</td>\n",
       "      <td>...</td>\n",
       "      <td>162.768585</td>\n",
       "      <td>156.709338</td>\n",
       "      <td>165.910468</td>\n",
       "      <td>161.416169</td>\n",
       "      <td>160.669898</td>\n",
       "      <td>134.76831</td>\n",
       "      <td>152.030562</td>\n",
       "      <td>158.18857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.625884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>123.529612</td>\n",
       "      <td>164.517583</td>\n",
       "      <td>129.065653</td>\n",
       "      <td>158.952364</td>\n",
       "      <td>134.011773</td>\n",
       "      <td>140.3666</td>\n",
       "      <td>109.411492</td>\n",
       "      <td>148.970714</td>\n",
       "      <td>132.894303</td>\n",
       "      <td>...</td>\n",
       "      <td>162.525034</td>\n",
       "      <td>157.725614</td>\n",
       "      <td>166.695206</td>\n",
       "      <td>161.458164</td>\n",
       "      <td>159.359102</td>\n",
       "      <td>134.815019</td>\n",
       "      <td>152.625922</td>\n",
       "      <td>155.300878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.341529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 City of London Barking & Dagenham      Barnet      Bexley  \\\n",
       "0          NaT      E09000001          E09000002   E09000003   E09000004   \n",
       "1   1995-01-01      11.669374          22.929155   20.218477   24.816722   \n",
       "2   1995-02-01      10.489509          23.213407   20.198028    24.75171   \n",
       "3   1995-03-01       10.09622          23.296649   19.993719   24.591089   \n",
       "4   1995-04-01       9.838522          24.143895   19.671936   24.556773   \n",
       "..         ...            ...                ...         ...         ...   \n",
       "332 2022-08-01     105.656778         159.148969  130.462619  153.835939   \n",
       "333 2022-09-01     105.585916         158.882915  131.219589  154.141978   \n",
       "334 2022-10-01     111.118669         161.444266   129.56221  156.530174   \n",
       "335 2022-11-01     120.979193         163.354786  127.436074  156.792996   \n",
       "336 2022-12-01     123.529612         164.517583  129.065653  158.952364   \n",
       "\n",
       "          Brent     Bromley      Camden     Croydon      Ealing  ...  \\\n",
       "0     E09000005   E09000006   E09000007   E09000008   E09000009  ...   \n",
       "1     16.859574   21.904319   15.711197   23.945162   19.371754  ...   \n",
       "2     17.028792   21.900587   15.526192   23.873468   19.616957  ...   \n",
       "3     17.027255   21.844735   15.626663   23.790837   19.734032  ...   \n",
       "4      17.25184   21.757596   15.602718   23.755384   19.930219  ...   \n",
       "..          ...         ...         ...         ...         ...  ...   \n",
       "332  132.974467  137.720556  112.758599  147.533774  130.272211  ...   \n",
       "333  138.299054  138.247239   111.46275  149.854291  130.979086  ...   \n",
       "334  136.663626  140.263355  109.337314  150.346196   131.38716  ...   \n",
       "335  135.304499  140.486192  108.891241  149.649804  131.817686  ...   \n",
       "336  134.011773    140.3666  109.411492  148.970714  132.894303  ...   \n",
       "\n",
       "     NORTH WEST YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS  \\\n",
       "0     E12000002          E12000003     E12000004     E12000005   \n",
       "1     32.312673          32.902881     29.638077     30.581484   \n",
       "2     32.288374          32.701203     29.968038      31.09431   \n",
       "3     32.662853          33.194459     29.533502      31.15789   \n",
       "4     32.540031          33.498403     30.015321     31.166557   \n",
       "..          ...                ...           ...           ...   \n",
       "332  159.012178          154.32148    162.906889    158.761363   \n",
       "333  160.581875         155.833508    164.153484    160.313329   \n",
       "334   161.72086         156.311794    164.433317    161.613768   \n",
       "335  162.768585         156.709338    165.910468    161.416169   \n",
       "336  162.525034         157.725614    166.695206    161.458164   \n",
       "\n",
       "    EAST OF ENGLAND      LONDON  SOUTH EAST  SOUTH WEST Unnamed: 47  \\\n",
       "0         E12000006   E12000007   E12000008   E12000009         NaN   \n",
       "1         24.839034   18.477406   24.171909   25.697918         NaN   \n",
       "2         24.791722    18.06588   24.057181    25.53397         NaN   \n",
       "3         24.606678   18.343629   24.207677   25.170817         NaN   \n",
       "4         24.780465   18.482254   24.400095   25.735903         NaN   \n",
       "..              ...         ...         ...         ...         ...   \n",
       "332      156.956941  135.437901  150.611387  156.952194         NaN   \n",
       "333      158.360732  135.536459  152.013503  157.716767         NaN   \n",
       "334      158.717415  134.039587  152.339754  158.535892         NaN   \n",
       "335      160.669898   134.76831  152.030562   158.18857         NaN   \n",
       "336      159.359102  134.815019  152.625922  155.300878         NaN   \n",
       "\n",
       "        England  \n",
       "0     E92000001  \n",
       "1     26.226925  \n",
       "2     26.174367  \n",
       "3     26.226192  \n",
       "4     26.418235  \n",
       "..          ...  \n",
       "332  153.525479  \n",
       "333  154.732941  \n",
       "334  155.140759  \n",
       "335  155.625884  \n",
       "336  155.341529  \n",
       "\n",
       "[337 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index_salesvol = pd.read_excel('https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls', sheet_name='Sales Volume', index_col= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>332</td>\n",
       "      <td>269</td>\n",
       "      <td>233</td>\n",
       "      <td>323</td>\n",
       "      <td>198</td>\n",
       "      <td>375</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>5801</td>\n",
       "      <td>4489</td>\n",
       "      <td>3990</td>\n",
       "      <td>4199</td>\n",
       "      <td>5812</td>\n",
       "      <td>7506</td>\n",
       "      <td>8809</td>\n",
       "      <td>5050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>7</td>\n",
       "      <td>95</td>\n",
       "      <td>327</td>\n",
       "      <td>207</td>\n",
       "      <td>220</td>\n",
       "      <td>326</td>\n",
       "      <td>194</td>\n",
       "      <td>342</td>\n",
       "      <td>242</td>\n",
       "      <td>...</td>\n",
       "      <td>6129</td>\n",
       "      <td>4349</td>\n",
       "      <td>4211</td>\n",
       "      <td>4633</td>\n",
       "      <td>5928</td>\n",
       "      <td>6873</td>\n",
       "      <td>8658</td>\n",
       "      <td>5113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>14</td>\n",
       "      <td>144</td>\n",
       "      <td>384</td>\n",
       "      <td>318</td>\n",
       "      <td>320</td>\n",
       "      <td>449</td>\n",
       "      <td>207</td>\n",
       "      <td>447</td>\n",
       "      <td>377</td>\n",
       "      <td>...</td>\n",
       "      <td>8375</td>\n",
       "      <td>6149</td>\n",
       "      <td>5840</td>\n",
       "      <td>6262</td>\n",
       "      <td>8374</td>\n",
       "      <td>9639</td>\n",
       "      <td>12177</td>\n",
       "      <td>7157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>7</td>\n",
       "      <td>109</td>\n",
       "      <td>304</td>\n",
       "      <td>253</td>\n",
       "      <td>249</td>\n",
       "      <td>362</td>\n",
       "      <td>174</td>\n",
       "      <td>377</td>\n",
       "      <td>270</td>\n",
       "      <td>...</td>\n",
       "      <td>6714</td>\n",
       "      <td>5338</td>\n",
       "      <td>4892</td>\n",
       "      <td>5218</td>\n",
       "      <td>7004</td>\n",
       "      <td>8053</td>\n",
       "      <td>10941</td>\n",
       "      <td>6359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>7</td>\n",
       "      <td>88</td>\n",
       "      <td>300</td>\n",
       "      <td>189</td>\n",
       "      <td>160</td>\n",
       "      <td>330</td>\n",
       "      <td>150</td>\n",
       "      <td>288</td>\n",
       "      <td>208</td>\n",
       "      <td>...</td>\n",
       "      <td>7330</td>\n",
       "      <td>5591</td>\n",
       "      <td>4963</td>\n",
       "      <td>5070</td>\n",
       "      <td>6395</td>\n",
       "      <td>6359</td>\n",
       "      <td>9457</td>\n",
       "      <td>6071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>121</td>\n",
       "      <td>295</td>\n",
       "      <td>245</td>\n",
       "      <td>167</td>\n",
       "      <td>393</td>\n",
       "      <td>147</td>\n",
       "      <td>358</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>8166</td>\n",
       "      <td>6096</td>\n",
       "      <td>5499</td>\n",
       "      <td>5827</td>\n",
       "      <td>7028</td>\n",
       "      <td>7324</td>\n",
       "      <td>10544</td>\n",
       "      <td>6841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>274</td>\n",
       "      <td>257</td>\n",
       "      <td>170</td>\n",
       "      <td>397</td>\n",
       "      <td>156</td>\n",
       "      <td>333</td>\n",
       "      <td>242</td>\n",
       "      <td>...</td>\n",
       "      <td>8146</td>\n",
       "      <td>6045</td>\n",
       "      <td>5379</td>\n",
       "      <td>5831</td>\n",
       "      <td>7521</td>\n",
       "      <td>7327</td>\n",
       "      <td>11392</td>\n",
       "      <td>6950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>17</td>\n",
       "      <td>101</td>\n",
       "      <td>286</td>\n",
       "      <td>232</td>\n",
       "      <td>150</td>\n",
       "      <td>416</td>\n",
       "      <td>211</td>\n",
       "      <td>357</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>7683</td>\n",
       "      <td>5748</td>\n",
       "      <td>5194</td>\n",
       "      <td>5545</td>\n",
       "      <td>7016</td>\n",
       "      <td>7193</td>\n",
       "      <td>10654</td>\n",
       "      <td>6749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "      <td>239</td>\n",
       "      <td>232</td>\n",
       "      <td>116</td>\n",
       "      <td>346</td>\n",
       "      <td>119</td>\n",
       "      <td>302</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>7081</td>\n",
       "      <td>5139</td>\n",
       "      <td>4573</td>\n",
       "      <td>4914</td>\n",
       "      <td>6168</td>\n",
       "      <td>6169</td>\n",
       "      <td>9606</td>\n",
       "      <td>6091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 City of London Barking & Dagenham     Barnet     Bexley  \\\n",
       "0          NaT      E09000001          E09000002  E09000003  E09000004   \n",
       "1   1995-01-01             17                 96        332        269   \n",
       "2   1995-02-01              7                 95        327        207   \n",
       "3   1995-03-01             14                144        384        318   \n",
       "4   1995-04-01              7                109        304        253   \n",
       "..         ...            ...                ...        ...        ...   \n",
       "330 2022-06-01              7                 88        300        189   \n",
       "331 2022-07-01             13                121        295        245   \n",
       "332 2022-08-01             14                108        274        257   \n",
       "333 2022-09-01             17                101        286        232   \n",
       "334 2022-10-01              9                 88        239        232   \n",
       "\n",
       "         Brent    Bromley     Camden    Croydon     Ealing  ... NORTH WEST  \\\n",
       "0    E09000005  E09000006  E09000007  E09000008  E09000009  ...  E12000002   \n",
       "1          233        323        198        375        303  ...       5801   \n",
       "2          220        326        194        342        242  ...       6129   \n",
       "3          320        449        207        447        377  ...       8375   \n",
       "4          249        362        174        377        270  ...       6714   \n",
       "..         ...        ...        ...        ...        ...  ...        ...   \n",
       "330        160        330        150        288        208  ...       7330   \n",
       "331        167        393        147        358        244  ...       8166   \n",
       "332        170        397        156        333        242  ...       8146   \n",
       "333        150        416        211        357        253  ...       7683   \n",
       "334        116        346        119        302        190  ...       7081   \n",
       "\n",
       "    YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND     LONDON  \\\n",
       "0            E12000003     E12000004     E12000005       E12000006  E12000007   \n",
       "1                 4489          3990          4199            5812       7506   \n",
       "2                 4349          4211          4633            5928       6873   \n",
       "3                 6149          5840          6262            8374       9639   \n",
       "4                 5338          4892          5218            7004       8053   \n",
       "..                 ...           ...           ...             ...        ...   \n",
       "330               5591          4963          5070            6395       6359   \n",
       "331               6096          5499          5827            7028       7324   \n",
       "332               6045          5379          5831            7521       7327   \n",
       "333               5748          5194          5545            7016       7193   \n",
       "334               5139          4573          4914            6168       6169   \n",
       "\n",
       "    SOUTH EAST SOUTH WEST Unnamed: 47    England  \n",
       "0    E12000008  E12000009         NaN  E92000001  \n",
       "1         8809       5050         NaN      47639  \n",
       "2         8658       5113         NaN      47880  \n",
       "3        12177       7157         NaN      67025  \n",
       "4        10941       6359         NaN      56925  \n",
       "..         ...        ...         ...        ...  \n",
       "330       9457       6071         NaN      53824  \n",
       "331      10544       6841         NaN      60366  \n",
       "332      11392       6950         NaN      61845  \n",
       "333      10654       6749         NaN      58713  \n",
       "334       9606       6091         NaN      52334  \n",
       "\n",
       "[335 rows x 49 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index_salesvol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdAu1A3YoH_r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKTyr437UgDa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
